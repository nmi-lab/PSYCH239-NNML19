<!doctype html>
<html>
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
<meta name="author" content="Emre Neftci">
<title>Neural Networks and Machine Learning</title>

<link rel="stylesheet" href="css/reset.css">
<link rel="stylesheet" href="css/reveal.css">
<link rel="stylesheet" href="css/theme/nmilab.css">
<link rel="stylesheet" type="text/css" href="https://cdn.rawgit.com/dreampulse/computer-modern-web-font/master/fonts.css">
<link rel="stylesheet" type="text/css" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css">
<link rel="stylesheet" type="text/css" href="lib/css/monokai.css">

<!-- Printing and PDF exports -->
<script>
  var link = document.createElement( 'link' );
  link.rel = 'stylesheet';
  link.type = 'text/css';
  link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
  document.getElementsByTagName( 'head' )[0].appendChild( link );
</script>
<script async defer src="https://buttons.github.io/buttons.js"></script>
</head>
<body>
<div class="reveal">
<div class="slides">

<!--
<section data-markdown><textarea data-template>
##                                                      
</textarea></section>

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/surrogate-gradient-learning/pytorch-lif-autograd/blob/master/tutorial01_dcll_localerrors.ipynb)
-->


<!-- .element: class="fragment" -->
<section data-markdown data-vertical-align-top data-background-color=#B2BA67><textarea data-template>
<h1> Neural Networks <br/>  and <br/> Machine Learning </h1>

### Instructor: Prof. Emre Neftci
![Emre Neftci](./img/neuralnetworks.png)

<center>https://canvas.eee.uci.edu/courses/21750</center>

[![Print](img/printer.svg)](?print-pdf)

</textarea>
</section>

<section data-markdown data-vertical-align-top><textarea data-template>
## Example: Keyword Detection
![](img/wake-word.svg)
![](img/some_soundwave.jpg)

- Every second, the microphone will collect roughly 44,000 samples. Each sample is a measurement of the amplitude of the sound wave  
- How to detect "Alexa" , "OK, Google" from the raw audio?
</textarea>
</section>

<section data-markdown data-vertical-align-top><textarea data-template>
## Example: Face Detection
![](img/face-detection-model.svg)
![](img/data_image_matrix.png)
- Every image is a collection of numbers indicating the intensity of the color channel at a given pixel
- How to detect the presence of a face in a picture?
</textarea>
</section>

<section data-markdown data-vertical-align-top><textarea data-template>
## Machine Learning Approach

![](img/ml-loop.svg)  
<ul>
  <li /> The goal of Machine Learning (ML) is to learn to solve a problem by extracting patterns from raw data 
  <li class=fragment /> The performance of ML models depends heavily on the representation of the data
  <li class=fragment /> Neural Networks are particularly efficient at learning these representations  
</ul>


</textarea>
</section>


<section data-markdown data-vertical-align-top><textarea data-template>
## History of Artificial Intelligence and Neural Networks
![](img/image.C0KVC0.png)

<div class=fragment>
Early AI shortcomings: 
<ul>
  <li/> Symbol based processing lacks domain-specific knowledge
  <li/> Combinatorial explosion: solutions to small problems did not scale to exponentially large problems.
  <li/> Solving a problem in principle is very different than solving it practically
</ul>
</div>

</textarea>
</section>

<section data-markdown><textarea data-template>
## AI's Moonshot
<img src=img/image.I6QZC0.png class="stretch"/>
</textarea>
</section>

<section>
<h2> Modern Artificial Intelligence and Machine Learning </h2>
<img src=img/image.X8Q2C0.png />
<img src=img/image.0IJ5C0.png />

<div class="fragment fade-in"><p class="pl">A lot of progress in machine learning can be attributed to better hardware and
  more data</p></div>
</section>






<section>
<h2>Connectionism and Neural Networks</h2><ul>
<img src="img/connectionnism.png"/>
<li class="fragment">At the heart of deep learning, there is an <b>artificial neural network</b></li>
<li class="fragment">Artificial neural networks are a subset of machine learning approaches using networks of simple (neuron-like) units.</li>
</ul>
</section>

<section data-markdown><textarea data-template>
## Machine Learning / Artificial Intelligence                                                     
<img src="img/venn_ml.png" class=stretch />

<blockquote>Deep learning is a kind of representation learning, which is in turn a kind of machine learning, which is used for many but not all approaches to AI" </blockquote>
<p class='ref'>(Goodfellow et al. 2016)</p>

</textarea>
</section>

<section data-markdown><textarea data-template>
## How does deep learning differ from other AI systems?

<img src=img/ml_flowchart.png class="stretch"/>
<p class='ref'>(Goodfellow et al. 2016)</p>


</textarea>
</section>



<section data-markdown><textarea data-template>
## Learning from Examples

Machine learning typically uses (large) ***datasets*** to learn to

- Recognize patterns (Classification)
- Generate patterns (Generation)
- Take Actions (Reinforcement Learning)
 
</textarea>
</section>

<section data-markdown><textarea data-template>
## Visual Recognition 

- Visual Recognition (Image Classification) is the most common task performed by neural networks
![](img/image_classification.png)
- Neural networks are trained using a dataset consisting of pairs of images and labels
</textarea>
</section>

<section data-markdown><textarea data-template>
## Example Dataset: MNIST and CIFAR
<div class="row">
<div class="column">
  <p style="text-align:center" >MNIST</p>
  <img src=img/mnist.png />
  </div>
  <div class="column">
  <p style="text-align:center" >CIFAR10</p>
  <img src=img/CIFAR-10.png />
  </div>
</div>

- MNIST/CIFAR10 are considered as the "Hello, World" example of deep learning

</textarea>
</section>

<section data-markdown><textarea data-template>
## Example Dataset: ImageNet
![](img/ImageNet.jpg)

- ImageNet: 1M images, 1000 classes, 469x387 pixels

<img src=img/ilsvrc.png class=small />

[![](http://image-net.org/index_files/logo.jpg)](http://www.image-net.org/)
</textarea></section>

<section data-markdown><textarea data-template>
## Example Dataset: CelebA                                                     
![](img/celebA.png)
- CelebA: large-scale face attributes dataset with more than 200K celebrity images, each with 40 attribute annotations.
</textarea>
</section>

<section data-markdown><textarea data-template>
## Beyond Image Classification

Machine Learning and neural networks can be applied to a wide variety of problems, such as: 

- Image Segmentation and Object Detection
- Text or Audio Classification
- Regression
- Translation
- Anomaly Detection
- Generation (Density Estimation)
</textarea></section>


<section data-markdown><textarea data-template>
## Other (Non-Visual) Datasets: 

- Speech Commands: 65,000 one-second long utterances of 30 short words, such as "Yes", "No", "Right", "Stop" 
- Penn Tree Bank (PTB) dataset: A text corpus that is parsed and annotated for natural language processing research <!-- .element: class="fragment" -->
- SMS Spam Collection Dataset: 5574 messages, tagged according being ham (legitimate) or spam <!-- .element: class="fragment" -->

</textarea>
</section>

<section data-markdown><textarea data-template>
## Convolutional Neural Networks: Image Classification
<img src="img/image_classification_imagenet.png" class="small"/>
<img src="img/lenet.png" class=stretch />
</textarea></section>

<section data-markdown><textarea data-template>
## YOLO: Object Detection
<img src="img/yolo.png" class="stretch"/>
</textarea></section>

<section data-markdown><textarea data-template>
## U-Nets: Image Segmentation
<img src="img/u-net-segmentation.png" class="small"/>
<img src="img/u-net-architecture.png" class="stretch" />
</textarea></section>

<section data-markdown><textarea data-template>
## Neural Style Transfer
<img src=img/art_style_transfer.png class=stretch />
</textarea></section>

<section data-markdown><textarea data-template>
## Neural Style Transfer: Deep Empathy
<img src=img/deep_empathy_style_transfer.png class="stretch" />
</textarea></section>

<section data-markdown><textarea data-template>
## Image Generation Using Generative Adversarial Networks (GAN)
<img src=img/image_generation_gan.png class=stretch />
</textarea></section>

<section data-markdown><textarea data-template>
## Visual Attention: Captioning
<img src=img/captioning.png class=stretch />
</textarea></section>

<section data-markdown><textarea data-template>
## Deep Reinforcement Learning: Game of Go
<img src=img/game_playing.png class=stretch />
<p class=ref>Silver, et al. 2016</p>
</textarea></section>

<section data-markdown><textarea data-template>
## Sequence Prediction

- Data can have a temporal structure
- Neural networks can be applied to learn and predict sequences
- Recurrent Neural Networks are one such example
<img src=img/sequence_prediction.png />
<p class=ref>C. Olah, 2015</p>
</textarea></section>

<section data-markdown><textarea data-template>
## Robot Control: Solving Rubik's Cube with a Robot Hand
<div class=row>
  <div class=column>
  <img src="img/openai_rubiks_arch.png" style="height:600px;max-height:600px" />
  </div>
  <div class=column>
<iframe src="https://www.youtube.com/embed/kVmp0uGtShk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen style='autoplay; max-height:500px;height:300px;width:100%;translate: scale(.1)'></iframe>
<p class=ref>OpenAI, 2019</p>
  </div>
</div>


</textarea></section>




<section data-markdown><textarea data-template>
## WaveNets: Voice and Music Generation
<img src=img/wavenet.png class=stretch />

- Parametric Text-To-Speech <audio controls="" src="https://storage.googleapis.com/deepmind-media/research/WaveNet/US%20English/parametric-1.wav"></audio>
- WaveNet <audio controls="" src="https://storage.googleapis.com/deepmind-media/research/WaveNet/US%20English/wavenet-1.wav"></audio>
<p class=ref>Van den Oord et al. 2016</p>
</textarea></section>

<section data-markdown><textarea data-template>
## Attention Networks:  Machine Translation
<img src=img/translation.png />
<img src="img/attention_bahdenau.png" class=stretch />
<p class=ref>Bahdenau, et al. 2015</p>
</textarea></section>

<section data-markdown><textarea data-template>
## ML/NN as Models for Understanding the Brain   

<img src="img/comparing_ann_and_brain.png" class=stretch />
<p class=ref>Blake, et al. 2019</p>

- ML/NN attempts to solve tasks that are similar to that of animals.
- Researchers use ML/NN to make hypotheses in the brain.

</textarea></section>

<section data-markdown><textarea data-template>
## The Explosion of Deep Learning
- Deep Learning has become the de facto solution for any representation learning problem
- Neural Information Processing Systems (NeurIPS) is the most prestigious conference in ML/AI
 - 13'000 Participant in 2019
 - In 2018, the main conference sold out after 12 minutes
<div class="row">
<div class="column">
  <img src=img/neurips_stats.png />
  </div>
  <div class="column">
    <img src=img/neurips2019_photo.JPG />
  </div>
</div>

</textarea>
</section>



<section data-markdown><textarea data-template>
## Books

- Ian Goodfellow, Yoshua Bengio, and Aaron Courville. Deep learning. MIT press, 2016.
- C.M. Bishop. Pattern recognition and machine learning. Springer-Verlag New York, Inc. Secaucus, NJ, USA, 2006.
- Wulfram Gerstner, Werner M Kistler, Richard Naud, and Liam Paninski. Neuronal dynamics: From single neurons to networks and models of cognition. Cambridge University Press, 4.
- E. O. Neftci, H. Mostafa, and F. Zenke. “Surrogate Gradient Learning in Spiking Neural Networks: Bringing the Power of Gradient-Based Optimization to Spiking Neural Networks”. IEEE Signal Processing Magazine 36.6 (Nov. 2019), pp. 51–63.

</textarea>
</section>




<section data-markdown><textarea data-template>
## Course Overview (Weeks 1-3)

- Historical perspective and Course logistics (Today) 
- Pattern Recognition Basics (1 Week) <!-- .element: class="fragment"  -->
 - Linear Regression, Classification (k-Nearest Neighbor, Perceptrons, Multilayer Perceptrons) 
- Machine Learning and Deep Learning (2 Weeks)  <!-- .element: class="fragment"  -->
 - Software and computer setup                 
 - Deep Neural Networks
 - Loss functions       
 - Optimization, Gradient Backpropagation                    
</textarea>
</section>

<section data-markdown><textarea data-template>
## Course Overview (Weeks 5-10)
- Applications (4 weeks) 
 - Visual Recognition: ConvNets     
 - Pattern Generation: Autoencoders, Variational Autoencoders and Generative Adversarial Networks            
 - Sequence Learning: Recurrent Neural Networks, LSTM, WaveNet                       
 - Natural Language Processing: Embeddings, Transformer Networks                               
- From Artificial Neural Networks to Biological Neural Nets: (1 week) <!-- .element: class="fragment"  -->
 - Spiking Neural Networks
 - Surrogate Gradient Learning   
- Final Projects Presentation (Last week)   <!-- .element: class="fragment"  -->

</textarea>
</section>

<section data-markdown><textarea data-template>
## Software and Assignments

This is a hands-on class, including programming assignments. All programming will be browser-based (no installation necessary): 

- Programming Language: Python 3
[![Python 3](https://communityblog.fedoraproject.org/wp-content/uploads/2015/11/Python-logo.png)](https://scipy-lectures.org/intro/)
 - Expected basic scientific programming skills in Python, and familiarity with the concepts in sections 1.1 through 1.4 in the [scipy lecture notes](http://www.scipy-lectures.org/intro/index.html).
- Programming Environment: Jupyter + Google Colaboratory
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/notebooks/welcome.ipynb)
- Deep Learning Environment: PyTorch 
[![PyTorch](https://upload.wikimedia.org/wikipedia/commons/9/96/Pytorch_logo.png)](http://pytorch.org)

</textarea>
</section>

<section data-markdown><textarea data-template>
## Final Project

- Topic in ML/NN:
  - Apply a neural network to a new dataset, or
  - Modify an algorithm on an existing dataset
- Week 10: 10+5 min presentation
- Finals Week: Project report, using NeurIPS conference paper template https://nips.cc/Conferences/2015/PaperInformation/StyleFiles
- Discuss topic with instructor before week 6
- Groups of two OK, but delineate contributions
</textarea>
</section>

<section data-markdown><textarea data-template>
## Final Project: Example Projects
- Visual / Sequence Recognition
  - Terrain Classificatio from Videos
  - Agent Localization using Video

- Computational Neuroscience
  - Three Factor Synaptic Plasticity Rules

- Classification/Regression on neuroimaging data
  - Artifact detection using EEG
  - Representation Similarity Analysis using Convnets and behavioral and neuroimaging data

<p class="pl">If possible, choose a topic that relates to your expertise and research</p>
</textarea>
</section>

</section>

<section data-markdown><textarea data-template>
# Perceptrons and Pattern Recognition

</textarea></section>



<section data-markdown><textarea data-template>
## History of Artificial Intelligence and Neural Networks
![](img/image.C0KVC0.png)                                                      
</textarea></section>


<section>
<h2>The First Artificial Neuron</h2><ul>
<li><p>In 1943, McCulloch and Walter Pitts propose the first artificial neuron, the Linear Threshold Unit. </p>
<img src="img/artificial_neuron.png"/>
</li>
<li><p>In the Linear Threshold Unit, $f$ is a step function: $f(x) = 1$ if $x&gt;0$</p>
</li>
<li>"Modern" artificial neurons are similar, but $f$ is typically a sigmoid or rectified linear function</li>
</ul>
</section>

<section>
<h2>Mathematical Model of the Artificial Neuron</h2>
<img src="img/artificial_neuron.png"/>
<ul>
<li>$x_i$  is the state of the input neurons</li>
<li>$w_i$ is the weight of the connection</li>
<li>$b$ is a bias</li>
<li>The total input to the neuron is: $ a = \sum_i w_i x_i +b $</li>
<li>The output of the neuron is: $ y = f(a) $</li>
<li>where $f$ is the activation function</li>
</ul>
</section>

<section data-markdown><textarea data-template>
<h2>The Perceptron</h2>
<img src="img/rosenblatt57_title.png" />
<blockquote>
<img src="img/rosenblatt57_quote1.png" class=small />
</blockquote>

</textarea></section>


<section>
<h2>The Perceptron</h2>
<ul>
  <li> The Perceptron is a special case of the artificial neuron where:
$$
\begin{eqnarray}
\mbox{y} & = & \begin{cases}
      -1 & \mbox{if } \sum_j w_j x_j + b \leq 0  \\\\
      1 & \mbox{if } \sum_j w_j x_j + b > 0
      \end{cases}
\end{eqnarray}
$$</li>
<img src=img/perceptron_weights.png />
<li> Three inputs $x_1$, $x_2$, $x_3$ with weights $w_1$, $w_2$, $w_3$, and bias $b$</li>
</ul>
</section>

<section data-markdown><textarea data-template>
## Perceptron Example
- Like McCulloch and Pitts neurons, Perceptrons can be hand-constructed to solve simple logical tasks
- Let's build a "sprinkler" that activates only if it is dry and sunny.
- Let's assume we have a humidity detector $x_0$ and a light detector $x_1$ (two inputs)
  - find $w_0$, $w_1$ and $b$

<img src="img/twonode_perceptron_template.svg"  style="height:400px"    />
</textarea></section>



<section data-markdown><textarea data-template>
## Perceptron Example
- The Sprinkler detects the state "dry" and "sunny": it is like an AND gate. 
![](img/and_gate.png) 
</textarea></section>

<!-- <section>
<h3>Programming A Linear Threshold Unit</h3>
<pre><code data-trim data-noescape>
x = np.array([1,-1,-1])
w = np.array([.1,.5,.8])
a = w[0]*x[0] + w[1]*x[1] + w[2]*x[2]
out = 1 if a>0 else -1 #This implements the step function
</code></pre>
</section> -->



<section data-markdown><textarea data-template>
## Logic Gates 

- Logic gates are (idealized) devices that perform one logical operation
- Common operations are AND, Not, and OR and can perform Boolean logic
- Using only Not AND (NAND) gates, any boolean function can be built. <!-- .element: class="fragment" -->
<img src=https://upload.wikimedia.org/wikipedia/commons/thumb/e/e6/NAND_ANSI_Labelled.svg/240px-NAND_ANSI_Labelled.svg.png />
<table>
<tr bgcolor="#ddeeff" align="center">
<td colspan="2"><b>INPUT</b></td>
<td><b>OUTPUT</b>
</td></tr>
<tr bgcolor="#ddeeff" align="center">
<td>A</td>
<td>B</td>
<td>A NAND B
</td></tr>
<tr bgcolor="#ddffdd" align="center">
<td>0</td>
<td>0</td>
<td>1
</td></tr>
<tr bgcolor="#ddffdd" align="center">
<td>0</td>
<td>1</td>
<td>1
</td></tr>
<tr bgcolor="#ddffdd" align="center">
<td>1</td>
<td>0</td>
<td>1
</td></tr>
<tr bgcolor="#ddffdd" align="center">
<td>1</td>
<td>1</td>
<td>0
</td></tr>
</table>
</textarea>
</section>

<section data-markdown><textarea data-template>
## NAND Perceptron 

- Let's Build a NAND Perceptron

<div class=row>
  <div class=column>
    <table>
    <tr bgcolor="#ddeeff" align="center">
    <td>$x_0$</td> <td>$x_1$</td> <td>$a~~~$</td> <td>$y~~~$ </td></tr>
    <tr bgcolor="#ddeeff" align="center">
    <tr bgcolor="#ddffdd" align="center">
    <td>0</td> <td>0</td> <td></td><td>1</td> </tr>
    <tr bgcolor="#ddffdd" align="center">
    <td>0</td> <td>1</td> <td>  </td><td>1</td> </tr>
    <tr bgcolor="#ddffdd" align="center">
    <td>1</td> <td>0</td> <td>  </td><td>1</td> </tr>
    <tr bgcolor="#ddffdd" align="center">
    <td>1</td> <td>1</td> <td>  </td><td>0</td> </tr>
    </table>
  </div>

  <div class=column>
    <img src="img/twonode_perceptron_template.svg"  style="height:400px"    />
  </div>
</div>

- Any Boolean can be built out of neuron models: Big deal! <!-- .element: class="fragment" -->
</textarea>
</section>


<section data-markdown><textarea data-template>
## The Perceptron Learning Algorithm
- Given inputs and targets, the Perceptron Algorithm can automatically learn the parameters so the output matches the target
- Number of Misclassified Samples as a Target for Learning
  ![](img/machine_learning_procedure.png)
<p class=pl>Perceptron weights are iteratively modified until number of misclassified samples is minimized</p>
</textarea></section>

<section data-markdown><textarea data-template>
## The Perceptron Criterion
- If a pattern $\mathbf{x}^n$ verifies $(\mathbf{x}^n \mathbf{w}) \hat{y}^n>0$, then it is correctly classified.
- This can be used as a cost function
  $$
  C_P(\mathbf{w}) = - \sum_{n\in \mathcal{M}} (\mathbf{x}^n \mathbf{w} ) \hat{y}^n
  $$
  where $\mathcal{M}$ is the set of misclassified samples. This cost function is also called the *Perceptron Criterion*
</textarea></section>

<section data-markdown><textarea data-template>
## The Perceptron Learning Rule
To minimize error, repeat for every misclassified data sample:

$$
  w_i  \leftarrow  w_i + \eta x_{i}^n y^n  
$$

$$
  b  \leftarrow  b + \eta y^n
$$

where $\eta$ is a "learning rate".
- If $y^n = \hat{y}^n$ no change
- If $y^n = 1$ and ${\hat{y}}^n = -1$: add inputs  $x_{ni}$ to weights
- If $y^n = -1$ and $\hat{y}^n = 1$: subtract inputs $x_{ni}$ from weights

- Let's implement it: [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://drive.google.com/open?id=1XOkJh_bB7K1oiKLTKJrj5iaRjYUSNy2w)
</textarea></section>












<section data-markdown><textarea data-template>
## The Perceptron Learning Rule
<img src=img/perceptron_convergence.png class=large />
<p class=ref>(Bishop, 2006 Pattern Recognition and Machine Learning)</p>

- Perceptron convergence theorem: if the training dataset is linearly separable, then the perceptron learning rule is guaranteed to find an exact solution
<p class=ref>(Rosenblatt, 1962, Principles of Neurodynamics: Perceptrons and the Theory of Brain Mechanisms)</p>
</textarea></section>

<section data-markdown><textarea data-template>
## Cost Functions

- The Cost (Error) function returns a number representing how well a model performed. 
- Perceptrons: Cost function = Number of Misclassified Samples
- Other common cost functions are
  - Mean Squared Error: $  C_\text{MSE}  = \frac{1}{2N} \sum_{n \in \text{train}} (\mathbf{y}^n - \mathbf{\hat{y}}^n) ^2 $ 
  - Cross-Entropy: $  C_{XENT} = - \frac1N \sum_{n \in \text{train}} \sum_k y_{k}^n  \log \hat{y}_{k}^n $
- The objective is to minimize the cost function.
- Cost functions can be minimized using an optimization algorithm
</textarea></section>


<section data-markdown><textarea data-template>
## Optimization Algorithm Gradient Descent
  
  Example: Find $x$ that minimizes $C(x) = x^2$

  <img src=img/quadratix_function.png class=small />

  - Incremental change in $\Delta x$:
  $$
  \begin{eqnarray} 
    \Delta C \approx \underbrace{\frac{\partial C}{\partial x}}_{\text{=Slope of }C(x)} \Delta x 
  \end{eqnarray}
  $$
  With $\Delta x = - \eta \frac{\partial C}{\partial x}$, $\Delta C \approx - \eta \left( \frac{\partial C}{\partial x} \right)^2$

  - Gradient Descent for finding the optimal $x$: 
  $
  \begin{eqnarray} 
    x \leftarrow x - \eta \frac{\partial C}{\partial x}
  \end{eqnarray} 
  $
</textarea></section>



<section data-markdown><textarea data-template>
## Smooth Activation Function

![](img/mlp_gradient_notext.png)

$$
\begin{eqnarray} 
  \Delta \mbox{y} \approx \sum_j \frac{\partial \mbox{y}}{\partial w_j} \Delta w_j 
\end{eqnarray}
$$

- Derivative of output: $\frac{\partial \mbox{y}}{\partial w_j} = \frac{\partial f(\mathbf{a})}{\partial w_j} = \frac{\partial f'(\mathbf{a})}{\partial \mathbf{a}} \frac{\partial\mathbf{a}}{\partial w_j}$
- The function $f'$ needs to be defined, i.e. $f$ must be continuous
- Problem with Perceptrons: A tiny $\Delta w$ can induce a flip (large $\Delta$ y)
</textarea></section>




<section data-markdown><textarea data-template>
## Deriving the Perceptron Rule from Gradient Descent

- The Perceptron criterion is specifically chosen to avoid the discontinuity problem
$$  C_P(\mathbf{w}) = - \sum_{n\in \mathcal{M}} ( \mathbf{x}^n \mathbf{w}) \hat{y}^n $$

- Gradient:
$$  \frac{\partial}{\partial w} C_P(\mathbf{w}) = - \sum_{n\in \mathcal{M}} \frac{\partial}{\partial w}( \mathbf{x}^n \mathbf{w}) \hat{y}_n $$

$$  \Delta \mathbf{w} = -\eta \frac{\partial}{\partial w} C_P(\mathbf{w}) =  \eta\sum_{n\in \mathcal{M}}  (\mathbf{x}^{n})^\top \hat{y}^n $$

- Note that biases can be considered as weights of an input that is always equal to 1

</textarea></section>

<section data-markdown><textarea data-template>
## XOR Gate

- XOR is another important logic gate
<table>
<tbody><tr bgcolor="#ddeeff" align="center">
<td colspan="2"><b>INPUT</b></td>
<td><b>OUTPUT</b>
</td></tr>
<tr bgcolor="#ddeeff" align="center">
<td>A</td>
<td>B</td>
<td>A XOR B
</td></tr>
<tr bgcolor="#ddffdd" align="center">
<td>0</td>
<td>0</td>
<td>0
</td></tr>
<tr bgcolor="#ddffdd" align="center">
<td>0</td>
<td>1</td>
<td>1
</td></tr>
<tr bgcolor="#ddffdd" align="center">
<td>1</td>
<td>0</td>
<td>1
</td></tr>
<tr bgcolor="#ddffdd" align="center">
<td>1</td>
<td>1</td>
<td>0
</td></tr></tbody>
</table>

- The XOR gate cannot be implemented using a Perceptron 

</textarea></section>

<section data-markdown><textarea data-template>
## Linear separability                                                     
  A perceptron is equivalent to a decision boundary.
  - A straight line can separate blue vs. red
  <img src=img/perceptron_rain_hyperplane.png class="small">
  - There is no straight line that can separate blue vs. red <!-- .element: class="fragment" -->
  <img src=img/perceptron_xor_hyperplane.png class="small">
  <p class="pl">Problems where a straight line can separate two classes are called <em>Linearly Separable</em></p>
</textarea></section>



</section>


<section data-markdown ><textarea data-template>
# Machine Learning Basics
</textarea></section>

<section data-markdown ><textarea data-template>
## Machine Learning Basics
- An ML algorithm is an algorithm that is able to learn from data 
- In ML, learning is our means of attaining the ability to perform some task. 
<!--  - Classification
 - Regression
 - Machine translation
 - Anomaly Detection
 - Denoising
 - Density Estimation 
 - Classiﬁcation with missing inputs -->
 <img src="img/ml-loop.svg" class="stretch" />
- The key ingredients of an ML algorithm are: <!-- .element: class="fragment" -->
 - Performance Measure (cost function)
 - Data
 - Model
 - Optimization algorithm

</textarea>
</section>

<section data-markdown><textarea data-template>
## Performance Measure and Cost Functions
- To evaluate the abilities of a model, we need a quantitative measure of its performance.
- The performance measure is specific to the task, for example: <!-- .element: class="fragment" -->
 - Accuracy for classification
 - Likelihood for density estimation
- Data is often separated in training sets and testing sets. Performance is evaluated on the testing set <!-- .element: class="fragment" -->
- Designing a tractable criterion to estimate performance is a key aspect of ML <!-- .element: class="fragment" -->

</textarea>
</section>


<section data-markdown><textarea data-template>
## Data                                                     
- ML algorithms studied in this course use a *dataset*, a collection of data points.
- ML algorithms can be broadly categorized as unsupervised or supervised
 - Unsupervised learning algorithms use datasets containing many features, then learn useful properties of the structure of this dataset
 - Supervised learning algorithms use datasets containing features, each of which is associated with a *label* or *target*
 - Note that collecting a labeled dataset is much more costly than an unlabeled one <!-- .element: class="fragment" -->
</textarea></section>

<section data-markdown><textarea data-template>
## Features and representations

- Each piece of information included in the dataset is a *feature*
- Features can be raw (e.g. pixel intensity), processed (e.g. frequency power) or higher-level (e.g. "number of limbs" or "frequency power"), or all of these combined.
- The collection of features is a *representation*
- The performance of the ML algorithm is highly dependent on the representation
</textarea></section>

<section data-markdown><textarea data-template>
##  Example Labeled Dataset: Iris Dataset
<img src=img/Iris_dataset_scatterplot.svg class=stretch />

- 150 Data Samples
- 4 Features: petal length, petal width, sepal length, sepal width
- 3 Classes:  Steosa, Vesicolor, Virginica
</textarea>
</section>

<section data-markdown><textarea data-template>
## Design Matrix

- A common way of describing a dataset is with a design matrix, a matrix containing a different example in each row. 
- Each column of the matrix corresponds to a different feature. 
- For example the Iris dataset design matrix is $X \in \mathbb{R}^{150\times 4}$
 - Each sample is a row vector of the design matrix: $X = [\mathbb{x}^1, \mathbb{x}^2, ..., \mathbb{x}^{150}]$, where each $x^n$ is a 4D vector
 - Labels *Steosa, Vesicolor, Virginica* can be represented using numerical values 0, 1 and 2, respectively.
 - This way labels can be described using a design matrix $Y \in \mathbb{N}^{150} = [y^1, y^2, ..., y^{150}]$, where $y^n$ is 0, 1 or 2

</textarea>
</section>

<section data-markdown><textarea data-template>
## Model

<ul>
  <li /> A model (as studied in this class) is some parameterized function that transforms inputs to outputs.
  <li /> Optionally, a model may be hierarchical and intructure several layers of representation 
  <li class=fragment /> A neural network can be viewed as a composition of simple functions that takes parameters and inputs and produces outputs
  <li class=fragment /> Deep learning generally requires the functions to be differentiable with respect to their parameters
</ul>

</textarea></section>

<section data-markdown><textarea data-template>
## Optimization Algorithms

<ul>
  <li /> Our goal is to minimize the cost function with respect to some dataset
  <li /> This is an optimization problem. Gradient Descent (BD) is one such approach. We will see several variants of GD.
  <li class=fragment/> Almost all deep learning models are trained with a form of GD.
    <ul><li />In Neural Networks, it is implemented using the <em>gradient backpropagation algorithm</em></ul>
</ul>
</textarea></section>


<section data-markdown><textarea data-template>
  ## Example Model: BOLD signal in fMRI
  
  <p> Blood oxygen level dependent (BOLD) signal in functional magnetic resonance imaging (fMRI) data assume that the BOLD signal is predominantly linear in space and time. </p>
  <img src=img/linear_fmri.jpeg style="height:200px"/>
  $$
  y^n = x^n \beta + \epsilon^n
  $$

  - $y_i$ is the $i$th BOLD signal measurement
  - $x_i$ is a value determined by the experiment design (retinal illumination here)
  - $\epsilon_i$ represents variation that is unexplained by the model
  <p class="ref">(Hansen et al. 2004)</p>
</textarea>
</section>

<section data-markdown><textarea data-template>
## Refresher: Linear Regression                            

- Linear regression is an ML algorithm. 
- The goal of linear regression is to build a system that can take a vector $\mathbf{x} \in \mathbb{R}^M$ as input and predict the value a scalar $y \in \mathbb{R}$ as its output using a linear function  
![](img/linear_regressin_example.png)
- It is a form of supervised learning, where $\mathbf{x}$ can be seen as features and $y$ as targets
</textarea>
</section>

<section data-markdown><textarea data-template>
## Refresher: Linear Regression                            
- Assuming that $\hat{y}$ is the predicted (one-dimensional) output, the linear regression model is defined as
$$
\hat{y} = \mathbf{x} \mathbf{w} = x_1 w_1 + x_2 w_2 + ... + x_M w_M
$$
where $\mathbf{w} \in \mathbb{R}^{M}$ is a vector of parameters (weights) to be "learned". 
- In linear regression, the performance measure is Mean Squared Error (MSE) evaluated on all samples $n$ of the test set <!-- .element: class="fragment"  -->
$$
MSE_{test} = \frac{1}{N_{test}} \sum_{n=1}^{N_{test}} (y^n-\hat{y}^n)^2
$$  <!-- .element: class="fragment"  -->
</textarea>
</section>

<section data-markdown><textarea data-template>
## Linear Regression Solution
- In matrix form:
$$
\hat{Y} = X_{test} \mathbf{w}, \quad MSE_{test} = \frac{1}{N_{test}} (Y_{test}-\hat{Y}_{test})^2
$$ 
- To make a ML algorithm, we could design an algorithm that trains the MSE on the training set
- But linear regression can be solved analytically by minimizing the MSE with respect to $\mathbf{w}$ 
$$
\mathbf{w} = (X_{train}^\top X_{train})^{-1} X_{train}^\top Y_{train}
$$ <!-- .element: class="fragment"  -->
- The model is then evaluated on $MSE_{test}$ <!-- .element: class="fragment"  -->

</textarea>
</section>


<section data-markdown><textarea data-template>
## Linear Models for Classification
#### (Sometimes called Logistic Regression)

- The Iris dataset has 3 classes. We can represent the output as a 3 dimensional vector describing the probability of being class 0, 1, or 2. Class 0 is the vector $(1,0,0)$, class 1 is the vector $(0,1,0)$ and class three is the vector $(0,0,1)$
- Because probabilities are bounded between 0 and 1, we use a sigmoid function around $XW$, where $W \in \mathbb{R}^{4\times 3}$ 
$$
\hat{Y} = \sigma(XW), \quad MSE = \frac{1}{2N} (Y-\hat{Y})^2
$$ <!-- .element: class="fragment"  -->
<img src=img/logistic-curve.svg style="height:100px"/>
- Due to the non-linearity, we cannot use the same MSE solution as with linear regression. This can be solved using GD.  <!-- .element: class="fragment"  -->

</textarea>
</section>

<section data-markdown><textarea data-template>
## Why does ML work?

<blockquote>How can we affect performance on the test set when we can observe only the training set? </blockquote>
The ﬁeld of statistical learning theory provides some answers.

</textarea>
</section>

<section data-markdown><textarea data-template>
## Generalization error 

In ML, the challenge is to perform well on new, previously unseen inputs. The ability to perform well on new inputs is called *generalization*. 

- Therefore, although we train on the training set, we actually care about the test set, i.e. minimizing the value of 
$$
MSE_{test} = \frac{1}{N_{test}} (X_{test} \mathbf{w}-\mathbf{y}_{test})^2
$$

- A central assumption here is that the training samples are "representative" of the test samples, in other words we require the two sets to be independent and identically distributed (iid).
- The distribution generating the train and test sets is called the *data-generating distribution*
- It is crucial to never use the test samples during training.

</textarea>
</section>


<section data-markdown><textarea data-template>
## Underfitting and Overfitting
![](img/dlbook_fig__5_2_capacity.png)

- The factors determining the performance of an ML algorithm are
 - Small training error (prevent underfitting)
 - Small gap between training error and test error (prevent overfitting)
</textarea>
</section>
 
<section data-markdown><textarea data-template>
## Model Capacity
![](img/dlbook_fig__5_3_capacity.png)
- Capacity changes the tendency of an ML algorithm to underfit/overfit 
- Roughly speaking, capacity is related to the complexity of the model (e.g. number of parameters)
- A model with larger capacity typically needs more training data to achieve good generalization error.

</textarea></section>




</div>
</div>






<!-- End of slides -->
<script src="../reveal.js/lib/js/head.min.js"></script>
<script src="js/reveal.js"></script>
<script>
Reveal.configure({ pdfMaxPagesPerSlide: 1, hash: true, slideNumber: true})
Reveal.initialize({
mouseWheel: false,
width: 1280,
height: 720,
margin: 0.0,
navigationMode: 'grid',
transition: 'fade',
menu: { // Menu works best with font-awesome installed: sudo apt-get install fonts-font-awesome
    themes: false,
    transitions: false,
    markers: true,
    hideMissingTitles: true,
    custom: [
              { title: 'Plugins', icon: '<i class="fa fa-external-link-alt"></i>', src: 'toc.html' },
              { title: 'About', icon: '<i class="fa fa-info"></i>', src: 'about.html' }
          ]
  },
chalkboard: { 
src:'slides_1-chalkboard.json',
penWidth : 1.0,
chalkWidth : 1.5,
chalkEffect : .5, 
readOnly: false, 
toggleChalkboardButton: { left: "80px" },
toggleNotesButton: { left: "130px" },
transition: 100,
theme: "whiteboard",
},
menu : { titleSelector: 'h1', hideMissingTitles: true,},
keyboard: {
67: function() { RevealChalkboard.toggleNotesCanvas() },	// toggle notes canvas when 'c' is pressed
66: function() { RevealChalkboard.toggleChalkboard() },	// toggle chalkboard when 'b' is pressed
46: function() { RevealChalkboard.reset() },	// reset chalkboard data on current slide when 'BACKSPACE' is pressed
68: function() { RevealChalkboard.download() },	// downlad recorded chalkboard drawing when 'd' is pressed
88: function() { RevealChalkboard.colorNext() },	// cycle colors forward when 'x' is pressed
89: function() { RevealChalkboard.colorPrev() },	// cycle colors backward when 'y' is pressed
},
dependencies: [
{ src: '../reveal.js/lib/js/classList.js', condition: function() { return !document.body.classList; } },
{ src: 'plugin/markdown/marked.js' },
{ src: 'plugin/markdown/markdown.js' },
{ src: 'plugin/notes/notes.js', async: true },
{ src: 'plugin/highlight/highlight.js', async: true },
{ src: 'plugin/math/math.js', async: true },
{ src: 'external-plugins/chalkboard/chalkboard.js' },
//{ src: 'external-plugins/menu/menu.js'},
{ src: 'node_modules/reveal.js-menu/menu.js' }
]
});
</script>



<script type="text/bibliography">
  @article{gregor2015draw,
    title={DRAW: A recurrent neural network for image generation},
    author={Gregor, Karol and Danihelka, Ivo and Graves, Alex and Rezende, Danilo Jimenez and Wierstra, Daan},
    journal={arXivreprint arXiv:1502.04623},
    year={2015},
    url={https://arxiv.org/pdf/1502.04623.pdf}
  }
</script>
</body>
</html>
